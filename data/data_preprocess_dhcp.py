import os
import glob
import time
import numpy as np
from tqdm import tqdm 
import argparse
import ants
import shutil
import scipy
import nibabel as nib
from scipy.io import loadmat



def ants_trans_to_mat(trans):
    """
    Compute the affine matrix from the Ants transformation.
    
    Inputs:
    - trans: Ants transformation (returned from Ants.registration)
    
    Returns:
    - affine: affine matrix, (4,4) numpy.array
    """
    fwd_transform = loadmat(trans['fwdtransforms'][0])
    m_matrix = fwd_transform['AffineTransform_float_3_3'][:9].reshape(3,3)# .T
    m_center = fwd_transform['fixed'][:,0]
    m_translate = fwd_transform['AffineTransform_float_3_3'][9:][:,0]
    m_offset = m_translate + m_center - m_matrix @ m_center

    # ITK affine to affine matrix
    affine = np.zeros([4,4])
    affine[:3,:3] = m_matrix
    affine[:3,-1] = -m_offset
    affine[3,:] = np.array([0,0,0,1])

    # LIP space to RAS coordinates
    affine[2,-1] = -affine[2,-1]
    affine[2,1] = -affine[2,1]
    affine[1,2] = -affine[1,2]
    affine[2,0] = -affine[2,0]
    affine[0,2] = -affine[0,2]
    return affine


def registration(
    img_move_ants,
    img_fix_ants,
    affine_fix,
    out_prefix,
    aff_metric='mattes',
    max_iter=5,
    min_dice=0.9,
    seed=10086,
    verbose=False,
):
    """
    Robust Ants rigid + affine registration from moving image to 
    fixed image. The registration is performed multiple times (max_iter)
    if the dices score < min_dice.
    
    Inputs:
    - img_move_ants: moving image to be aligned, Ants image
    - img_fix_ants: target fixed image, Ants image
    - affine_fix: affine matrix of fixed image, (4,4) numpy.array
    - out_prefix: prefix of output transformation files 
    - aff_metric: metric used for optimization ['mattes','meansquares', 'gc']
    - max_iter: maximum iterations for registration
    - min_dice: minimum required dice score after registration
    - seed: random seed for reproducing results
    - verbose: if report
    
    Returns:
    - img_align_ants: aligned image, Ants image
    - affine_mat: affine matrix after registration, (4,4) numpy.array
    - trans_rigid: transformation for rigid registration, Ants.transformation
    - trans_affine: transformation for affine registration, Ants.transformation
    """
    # set random seed
    np.random.seed(seed)
    for n in range(max_iter):
        # use different random seed for each iteration
        ants_seed = np.random.randint(1,10000)
        
        # affine transformation
        trans_ants = ants.registration(
            fixed=img_fix_ants,
            moving=img_move_ants,
            type_of_transform='AffineFast', 
            aff_metric=aff_metric,
            outprefix=out_prefix+'_affine_',
            random_seed=ants_seed,
            verbose=verbose)
        img_align_ants = ants.apply_transforms(
            fixed=img_fix_ants,
            moving=img_move_ants,
            transformlist=trans_ants['fwdtransforms'],
            interpolator='linear')
        affine_mat = ants_trans_to_mat(trans_ants)

        # compute the dice overlap with atlas image
        mask_align = (img_align_ants.numpy()>0).astype(np.float32)
        mask_fix = (img_fix_ants.numpy()>0).astype(np.float32)
        dice_align = 2 * (mask_align * mask_fix).sum()\
            / (mask_align + mask_fix).sum()
        if dice_align >= min_dice:
            break
        
    # affine matrix after affine registration
    affine_mat = affine_mat @ affine_fix
    
    return img_align_ants, affine_mat, trans_ants, dice_align


def cut_brain(seg):
    '''
    Split and fill brain hemispheres for fetal brain tssue segmentations 
    generated by the BOUNTI pipeine.
    https://elifesciences.org/reviewed-preprints/88818
    
    A PCA-based approach is used. 
    For original MIRTK implementation please see:
    https://github.com/BioMedIA/MIRTK/blob/master/Applications/src/cut-brain.cc
    '''
    
    # compute the cutting plane
    points = np.array(np.where(seg>0)).T
    centers = points.mean(0)
    covar = (points - centers).T @ (points - centers)
    _, eigen_vec = np.linalg.eig(covar.T)
    
    # the normal vector should be similar to [1,0,0]
    # based on the symmetry of the brain
    # so we find the largest absolute value of the first axis
    idx = np.argmax(np.abs(eigen_vec[0]))
    normals = eigen_vec[:,idx]

    # make sure positive direction
    normals = normals * np.sign(normals[0])
    normals = normals / np.linalg.norm(normals)
    bias = (centers * normals).sum()
    
    # cut all voxels
    p_all = np.array(np.where(seg>0)).T
    hemi = p_all @ normals - bias
    left_id = np.stack(np.where(hemi<0))
    right_id = np.stack(np.where(hemi>=0))
    lid = p_all[left_id[0]]
    rid = p_all[right_id[0]]
    seg_split = np.zeros_like(seg)
    seg_split[lid[:,0], lid[:,1], lid[:,2]] = 1
    seg_split[rid[:,0], rid[:,1], rid[:,2]] = 2

    return seg_split



if __name__ == "__main__":

    # ------ load arguments ------ 
    parser = argparse.ArgumentParser(description="CoSeg")

    parser.add_argument('--orig_dir', default='YOUR_DHCP_DATA/', type=str, help="directory of the dHCP fetal data")
    parser.add_argument('--save_dir', default='./data/dhcp/', type=str, help="directory to save the preprocessed data")
    args = parser.parse_args()

    orig_dir = args.orig_dir
    save_dir = args.save_dir

    # ------ randomly split train/valid/test data ------ 
    np.random.seed(12345)
    subj_list = sorted(glob.glob(orig_dir+'sub-*'))
    subj_permute = np.random.permutation(len(subj_list))
    n_train = int(len(subj_list) * 0.6)
    n_valid = int(len(subj_list) * 0.1)
    n_test = len(subj_list) - n_train - n_valid
    print("Number of training data:", n_train)
    print("Number of validation data:", n_valid)
    print("Number of testing data:", n_test)

    train_list = subj_permute[:n_train]
    valid_list = subj_permute[n_train:n_train+n_valid]
    test_list = subj_permute[n_train+n_valid:]
    data_list = [train_list, valid_list, test_list]
    data_split = ['train', 'valid', 'test']

    for n in range(3):
        for i in data_list[n]:
            subj_id = subj_list[i].split('/')[-1]
            subj_dir = save_dir+data_split[n]+'/'+subj_id
            if not os.path.exists(subj_dir):
                os.makedirs(subj_dir)

    # load 36-week dHCP atlas
    img_fix_ants = ants.image_read(
        '../template/dhcp_fetal_week36_t2w.nii.gz')
    affine_fix = nib.load(
        '../template/dhcp_fetal_week36_t2w.nii.gz').affine
    img_fix = img_fix_ants.numpy()
    min_regist_dice = 0.90


    for data_split in ['train', 'valid', 'test']:
        split_dir = save_dir + data_split+'/'
        subj_list = sorted(glob.glob(split_dir+'sub-*'))

        for i in tqdm(range(len(subj_list[:3]))):
            subj_dir = subj_list[i]
            subj_id = subj_dir.split('/')[-1]
            print(orig_dir+subj_id+'/'+subj_id+'_T2w.nii.gz')

            # ------ load images ------
            img_orig_nib = nib.load(orig_dir+subj_id+'/'+subj_id+'_T2w.nii.gz')
            affine_orig = img_orig_nib.affine
            # brain masks and tissue segmentations generated by BOUNTI pipeline
            brain_mask_nib = nib.load(orig_dir+subj_id+'/'+subj_id+'_T2w-mask-bet-1.nii.gz')
            tissue_seg_nib = nib.load(orig_dir+subj_id+'/'+subj_id+'_T2w-mask-brain_bounti-19.nii.gz')
            img_orig = img_orig_nib.get_fdata()
            brain_mask = brain_mask_nib.get_fdata()
            tissue_seg = tissue_seg_nib.get_fdata()
            # brain extracted image
            img_brain = img_orig * brain_mask

            # ------ create cortical ribbon segmentations ------ 
            seg_wm_left = np.isin(tissue_seg,[5,7,14,16]).astype(float)
            seg_wm_right = np.isin(tissue_seg,[6,8,15,17]).astype(float)
            seg_gm_left = np.isin(tissue_seg,[3]).astype(float)
            seg_gm_right = np.isin(tissue_seg,[4]).astype(float)
            seg_cavum = np.isin(tissue_seg,[9]).astype(float)
            seg_ventricle = np.isin(tissue_seg,[18]).astype(float)
            ribbon_split = seg_wm_left + 2 * seg_wm_right + 3 * seg_gm_left + 4 * seg_gm_right
            ribbon = ribbon_split + cut_brain(seg_cavum) + cut_brain(seg_ventricle)

            # ------ affine registration ------
            # use brain-extracted image as moving image
            img_move_ants = ants.image_read(
                orig_dir+subj_id+'/'+subj_id+'_T2w.nii.gz')
            img_move_ants = ants.from_numpy(
                img_brain,
                origin=img_move_ants.origin,
                spacing=img_move_ants.spacing,
                direction=img_move_ants.direction)
            ribbon_move_ants = ants.from_numpy(
                ribbon,
                origin=img_move_ants.origin,
                spacing=img_move_ants.spacing,
                direction=img_move_ants.direction)

            # perform registration
            img_align_ants, affine_align, trans_ants, dice_align =\
            registration(
                img_move_ants, img_fix_ants, affine_fix,
                out_prefix=subj_dir+'/'+subj_id)
            img_align = img_align_ants.numpy()
            if dice_align >= min_regist_dice:
                print('Dice after registration: {}'.format(dice_align))
            else:
                print('Error! Affine registration failed!')
                print('Expected Dice>{} after registraion, got Dice={}.'.format(
                    min_regist_dice, dice_align))

            # affinely align the segmentation
            ribbon_align_ants = ants.apply_transforms(
                fixed=img_fix_ants,
                moving=ribbon_move_ants,
                transformlist=trans_ants['fwdtransforms'],
                interpolator='genericLabel')
            ribbon_align = ribbon_align_ants.numpy()    

            # check dice score
            mask_align = (img_align>0).astype(np.float32)
            mask_fix = (img_fix>0).astype(np.float32)
            dice_align = 2*(mask_align*mask_fix).sum()/(mask_align+mask_fix).sum()

            os.remove(subj_dir+'/'+subj_id+'_affine_0GenericAffine.mat')

            # save data
            img_align_nib = nib.nifti1.Nifti1Image(
                img_align.astype(np.float32), affine_align)
            ribbon_align_nib = nib.nifti1.Nifti1Image(
                ribbon_align.astype(np.float32), affine_align)

            nib.save(img_align_nib, subj_dir+'/'+subj_id+'_T2w_affine.nii.gz')
            nib.save(ribbon_align_nib, subj_dir+'/'+subj_id+'_ribbon_affine.nii.gz')
    print('Done.')
